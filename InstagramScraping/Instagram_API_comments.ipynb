{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f239ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from apify_client import ApifyClient\n",
    "import time\n",
    "import re\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "#import json\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import pandas as pd\n",
    "\n",
    "# Get the 30 first posts of the 25 players\n",
    "playersList = [\"vinijr\", \"marcelotwelve\", \"marega11\", \"pwebo99\", \"romelulukaku\", \"sterling7\", \"balotelliclub\", \"samueletoo\", \"toniruediger\",\n",
    "         \"marcusrashford\", \"hamitaltintopofficial\"]\n",
    "\n",
    "sec_playerList = [\"neymarjr\", \"danialves\", \"mahamadoudiarra_\", \"antony00\", \"luissuarez9\", \"diego.costa\", \"antogriezmann\", \"mouctar_dkh\",\n",
    "                 \"mujaids4\", \"williaaaams11\", \"andressaalves9oficial\", \"jeffersonlerma\", \"samumtiti\", \"p.diop23\"]\n",
    "\n",
    "playersList = playersList + sec_playerList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8965d",
   "metadata": {},
   "source": [
    "### Trying to access instagram API and extracting the comments without success :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98022c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# extract de media_id\n",
    "access_token = \"XXX\"\n",
    "shortcode = \"CnxWUqyMChM\"\n",
    "\n",
    "# Construct the API endpoint URL\n",
    "url = f\"https://graph.instagram.com/v15.0/vinijr/media?access_token={access_token}\"\n",
    "\n",
    "# Make a GET request to the API\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "# Parse the JSON data\n",
    "#data = json.loads(response.text)\n",
    "\n",
    "# Extract the media ID\n",
    "#media_id = data['data']['id']\n",
    "\n",
    "#print(media_id)\n",
    "\n",
    "\"\"\"\n",
    "# extract de comments using media_id \n",
    "access_token = \"XXX\"\n",
    "media_id = \"ChMVDO9s-YA\"\n",
    "\n",
    "# Construct the API endpoint URL\n",
    "url = f\"https://api.instagram.com/v15.0/media/{media_id}/comments?access_token={access_token}\"\n",
    "\n",
    "# Make a GET request to the API\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response)\n",
    "\n",
    "# Parse the JSON data\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Extract the comments\n",
    "comments = data['data']\n",
    "\n",
    "# Print the comments\n",
    "for comment in comments:\n",
    "    print(comment['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c17073",
   "metadata": {},
   "source": [
    "### Using ApifyClient to extract info about the selected players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956efaa",
   "metadata": {},
   "source": [
    "All commented lines have been used but are commented to avoid overwriting variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64080c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the ApifyClient with API token\n",
    "client = ApifyClient(\"XXXXX\") # your apify client\n",
    "\n",
    "# Creating a function that gets the first 30 post-ids of the passed player\n",
    "def getApiInfo(player):\n",
    "    lista = []\n",
    "    # Prepare the actor input\n",
    "    run_input = {\n",
    "        \"username\": [player],\n",
    "        \"resultsLimit\": 30,\n",
    "    }\n",
    "\n",
    "    # Run the actor and wait for it to finish\n",
    "    run = client.actor(\"zuzka/instagram-post-scraper\").call(run_input=run_input)\n",
    "\n",
    "    # Fetch and print actor results from the run's dataset (if there are any)\n",
    "    for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "        lista.append(item)\n",
    "    return lista\n",
    "\n",
    "# Returns a dict with 30 posts of each player\n",
    "def getAllInfo(players_list):\n",
    "    players_info = dict()\n",
    "    for player in players_list:\n",
    "        tmp_list = getApiInfo(player)\n",
    "        players_info[player] = tmp_list\n",
    "    return players_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aeb725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#players_info_new = getAllInfo(sec_playerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088f2a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saving all the info received from apify calls (players info) into a pickle object.\n",
    "\"\"\"# Saving all the players' info to a pickle object in order to access to the data later\n",
    "with open('total_players_insta.pickle', 'wb') as handle:\n",
    "    pickle.dump(total_players_insta, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Checking if it's saved\n",
    "with open('total_players_insta.pickle', 'rb') as handle:\n",
    "    total_players_insta_test = pickle.load(handle)\n",
    "\n",
    "print(total_players_insta == total_players_insta_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two previous dicts with different data of 2 different set of players into one single collection\n",
    "#total_players_insta = {**players_info,**players_info_new}\n",
    "#print(total_players_insta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ac311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading it once it's already stored\n",
    "with open('total_players_insta.pickle', 'rb') as handle:\n",
    "    players_info = pickle.load(handle)\n",
    "\n",
    "print(players_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4b677",
   "metadata": {},
   "source": [
    "### Using chromeDriver to log in to Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6f05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open chrome\n",
    "driver = webdriver.Chrome(\"./chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "# Open instagram's page\n",
    "main_url = \"https://www.instagram.com/\"\n",
    "driver.get(main_url)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Log in, in order to be able to extend the comments with the (+) button\n",
    "f=open(\"credentials.txt\",\"r\")\n",
    "lines=f.readlines()\n",
    "username=lines[0]\n",
    "password=lines[1]\n",
    "f.close()\n",
    "\n",
    "# Accepting and refusing starting page buttons\n",
    "cookies_button = driver.find_element(By.CLASS_NAME, '_a9--._a9_1')\n",
    "cookies_button.click()\n",
    "\n",
    "# element = WebDriverWait(driver, 5).until(lambda x: x.find_element(By.NAME, \"username\"))\n",
    "\n",
    "username_input = driver.find_element(By.NAME, \"username\")\n",
    "password_input = driver.find_element(By.NAME, \"password\")\n",
    "username_input.send_keys(username)\n",
    "password_input.send_keys(password)\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "join_button = driver.find_element(By.CLASS_NAME , '_acan._acap._acas._aj1-')\n",
    "join_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81412d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking pop-up buttons once logged in\n",
    "not_now_button = driver.find_element(By.CLASS_NAME, \"_acan._acap._acas._aj1-\")\n",
    "not_now_button.click()\n",
    "\n",
    "not_now_notifications_button = driver.find_element(By.CLASS_NAME, \"_a9--._a9_1\")\n",
    "not_now_notifications_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197b435a",
   "metadata": {},
   "source": [
    "### Using selenium and BeautifulSoup to extract instagram comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f56962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the 30 first postURLs of username\n",
    "def getPostURL_by_username(username):\n",
    "    postURLs_by_username = list()\n",
    "    \n",
    "    for post in players_info[username]:\n",
    "        postURLs_by_username.append(post['url'])\n",
    "        \n",
    "    return postURLs_by_username\n",
    "\n",
    "# Creating a dict collection of  player: postURLs\n",
    "def getAllPostURL(players_list):\n",
    "    allPostURLs = dict()\n",
    "    \n",
    "    for player in players_list:\n",
    "        allPostURLs[player] = getPostURL_by_username(player)\n",
    "        \n",
    "    return allPostURLs\n",
    "\n",
    "allPostsURL = getAllPostURL(playersList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a843d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scrap the comments of an URL\n",
    "\"\"\"\n",
    "def extract_comments(player, url):\n",
    "    driver.get(url)\n",
    "    lista = []\n",
    "    \n",
    "    # Click the more comments button 60 times\n",
    "    more_button = driver.find_element(By.CLASS_NAME, '_ab8w._ab94._ab99._ab9h._ab9m._ab9p._abcj._abcm')\n",
    "    more_button.click()\n",
    "    try:\n",
    "        i = 0\n",
    "        while (i < 60):\n",
    "            wait = WebDriverWait(driver, 40)\n",
    "            more_button = driver.find_element(By.CLASS_NAME, '_ab8w._ab94._ab99._ab9h._ab9m._ab9p._abcj._abcm')\n",
    "            more_button.click()\n",
    "            time.sleep(2)\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"can't load more button\")\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract the comments\n",
    "    comments = soup.find_all('div', {'class': '_a9zs'})\n",
    "\n",
    "    # Store the comments in a df row\n",
    "    for comment in comments:\n",
    "        lista.append([player, comment.text, 'instagram'])\n",
    "        \n",
    "    return lista\n",
    "\n",
    "\"\"\"\n",
    "Extract the comments of all the players in the df\n",
    "\"\"\"\n",
    "def extract_all_comments(player, df):\n",
    "    for url in allPostsURL[player]:\n",
    "        try:\n",
    "            rows_list = extract_comments(player, url)\n",
    "\n",
    "            for row in rows_list:\n",
    "                df.loc[len(df)] = row\n",
    "        except:\n",
    "            print(\"comments not found for this post\")\n",
    "    return df\n",
    "\n",
    "# Given a list of players, iterate over the post codes and exract the comments\n",
    "def extract_all(lista):\n",
    "    df = pd.DataFrame(columns=['player', 'comment', 'media'])\n",
    "    \n",
    "    for player in lista:\n",
    "        try:\n",
    "            df = extract_all_comments(player, df)\n",
    "        except:\n",
    "            print(\"comments not found for player\", player)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "# Now it's possible to pass a complete list of players and It won't fail (no need slicing)\n",
    "try1 = playersList[:3] # 3 first players\n",
    "try2 = playersList[3:6]\n",
    "try3 = playersList[6:9]\n",
    "try4 = playersList[9:12]\n",
    "try5 = playersList[12:15]\n",
    "try6 = playersList[15:16]\n",
    "final_try = playersList[15:] # all the players left\n",
    "final_df = extract_all(final_try)\n",
    "final_df.to_csv(\"C:/Users/jorge/TFG/Football_players_offenses/InstagramScraping/comments_dataset_10p.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the dataset looks after creating it with all the football players posts' comments.\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56784a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the datasets created on different tries (extract_all)\n",
    "dataset1 = pd.read_csv(\"InstagramScraping/comments_dataset1.csv\")\n",
    "dataset2 = pd.read_csv(\"InstagramScraping/comments_dataset2.csv\")\n",
    "dataset3 = pd.read_csv(\"InstagramScraping/comments_dataset3.csv\")\n",
    "dataset4 = pd.read_csv(\"InstagramScraping/comments_dataset4.csv\")\n",
    "dataset5 = pd.read_csv(\"InstagramScraping/comments_dataset5.csv\")\n",
    "dataset6 = pd.read_csv(\"InstagramScraping/comments_dataset_lukaku.csv\")\n",
    "dataset7 = pd.read_csv(\"InstagramScraping/comments_dataset_10p.csv\")\n",
    "final_dataset = pd.concat([dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7])\n",
    "final_dataset\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43bfe5",
   "metadata": {},
   "source": [
    "### A bit of data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the emojis from the comments \n",
    "def remove_emojis(input_string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs, including the white heart emoji 🤍\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001F90D\"  # the white heart emoji 🤍\n",
    "        u\"\\U0001F979\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', input_string)\n",
    "\n",
    "# Function to remove symbols from the comments\n",
    "def remove_non_letters(text):\n",
    "    return \"\".join(c for c in text if c.isalnum() or c.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing comments with emojis for '' and removing all the symbols that are not letters\n",
    "final_dataset['comment'] = final_dataset['comment'].apply(remove_emojis).apply(remove_non_letters)\n",
    "\n",
    "# Removing all the rows that are empty ('')\n",
    "final_dataset.drop(final_dataset[final_dataset['comment'] == ''].index, inplace = True)\n",
    "\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8f7a0",
   "metadata": {},
   "source": [
    "### Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting it to avoid overwritting the dataset\n",
    "\"\"\"# Saving the complete dataset to a pickle object in order to access to the data later\n",
    "with open('final_dataset.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Checking if it's saved\n",
    "with open('final_dataset.pickle', 'rb') as handle:\n",
    "    final_dataset_test = pickle.load(handle)\n",
    "\n",
    "print(all(dataset == final_dataset_test))\n",
    "\n",
    "if all(dataset == final_dataset_test):\n",
    "    dataset.to_csv(\"C:/Users/jorge/TFG/Football_players_offenses/CleanTranslateDataset/final_dataset.csv\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d057d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Reading the dataset once it's already stored\n",
    "with open('CleanTranslateDataset/final_dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "\n",
    "dataset.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
