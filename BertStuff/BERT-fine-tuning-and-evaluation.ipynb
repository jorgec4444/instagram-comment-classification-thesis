{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r bert_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a930d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print('*'*10)\n",
    "print(f'_CUDA version: ')\n",
    "!nvcc --version\n",
    "print('*'*10)\n",
    "print(f'CUDNN version: {torch.backends.cudnn.version()}')\n",
    "print(f'Available GPU devices: {torch.cuda.device_count()}')\n",
    "print(f'Device Name: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # NumPy es una biblioteca utilizada para trabajar con matrices y realizar operaciones numéricas eficientes.\n",
    "import pandas as pd  # Pandas es una biblioteca utilizada para la manipulación y análisis de datos, proporcionando estructuras de datos flexibles y herramientas para la limpieza, transformación y manipulación de datos.\n",
    "import time  # El módulo time proporciona funciones para trabajar con el tiempo, como medir el tiempo de ejecución de un código.\n",
    "import datetime  # El módulo datetime proporciona clases para trabajar con fechas y horas de una manera más conveniente.\n",
    "import warnings  # El módulo warnings se utiliza para manejar advertencias y controlar su comportamiento en el código.\n",
    "import torch  # PyTorch es un marco de aprendizaje automático de código abierto que proporciona herramientas para construir y entrenar modelos de aprendizaje profundo.\n",
    "import torch.nn as nn  # El módulo torch.nn proporciona clases y funciones para construir redes neuronales en PyTorch.\n",
    "from sklearn.model_selection import train_test_split  # train_test_split es una función que se utiliza para dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "from sklearn.metrics import classification_report  # classification_report es una función que muestra un informe detallado de las métricas de rendimiento de un modelo de clasificación.\n",
    "import transformers  # Transformers es una biblioteca popular para el procesamiento de lenguaje natural (NLP) y el aprendizaje automático.\n",
    "from transformers import AutoModel, BertTokenizerFast  # AutoModel es una clase que proporciona un modelo de lenguaje preentrenado, y BertTokenizerFast es una clase utilizada para tokenizar texto en BERT.\n",
    "import pickle  # El módulo pickle se utiliza para la serialización y deserialización de objetos en Python, lo que permite guardar y cargar modelos o datos en disco.\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler  # Estas clases se utilizan para crear conjuntos de datos, cargar datos en modelos de PyTorch y generar muestras aleatorias o secuenciales para el entrenamiento.\n",
    "from transformers import AdamW  # AdamW es un optimizador utilizado para ajustar los pesos de los modelos de Transformers durante el entrenamiento.\n",
    "from sklearn.utils.class_weight import compute_class_weight  # compute_class_weight es una función que calcula los pesos de clase para abordar el desequilibrio de clases en el aprendizaje automático.\n",
    "from tqdm.auto import tqdm  # tqdm es una biblioteca utilizada para crear barras de progreso interactivas en bucles y tareas largas en Python.\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./Sentiment/training.1600000.processed.noemoticon.csv',delimiter=',', encoding='ISO-8859-1')\n",
    "df = pd.read_csv('./definitive_dataset.csv',delimiter=',', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df4c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6435d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.columns=['sentiment','id','date','query','username','text']\n",
    "df.columns=['player', 'text', 'media', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3222ba",
   "metadata": {},
   "source": [
    "### 1 - not ofensive\n",
    "### 0 - ofensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa845d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done only in the case of the dataset training.1600000.processed.noemoticon.csv because the sentiment was 0 or 4,\n",
    "# for BERT model it has to be 0 or 1. The dataset wich I'm using now it's already labeled with 0 and 1's.\n",
    "#df.loc[df['sentiment'] == 4, 'sentiment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['sentiment'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['sentiment'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16046ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "batch_size = 32 # 160000_dataset size 256 , 64 with model bert_trained3 acc 0,71  and with bert_trained2 acc 0,60 y algo\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ad47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74c102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to CPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699985a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47058cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "total_epochs = 10 # total_epochs = 15 the bert_trianed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c46b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "      # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080671cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    # Convert seconds to hh:mm:ss format\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"{:02d}:{:02d}:{:02d}\".format(int(h), int(m), int(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "        \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time())\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            \n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f60938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in tqdm(range(total_epochs), total=total_epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7095472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model, './bert_trained_3_32batch')\n",
    "\n",
    "# Load the model\n",
    "model = torch.load('./bert_trained_3_32batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e991b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pepe_df = df.copy()[:60]\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(pepe_df['text'], pepe_df['sentiment'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=pepe_df['sentiment'])\n",
    "\n",
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "print(tokens_train['attention_mask'])\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "    model.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        decoded_sent = tokenizer.decode(sent_id[0], skip_special_tokens=True)\n",
    "        print(decoded_sent)\n",
    "        \n",
    "        # model predictions\n",
    "        preds = model(sent_id, mask)\n",
    "        \n",
    "        prob = torch.softmax(preds, dim=1)[0]\n",
    "\n",
    "        if prob[0] > prob[1]:\n",
    "            print(\"Negative\")\n",
    "        else:\n",
    "            print(\"Positive\")\n",
    "            \n",
    "        preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03530d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_offensive(text, model):\n",
    "    tokenized_text = tokenizer.batch_encode_plus([text], max_length = 25,\n",
    "                                                 truncation=True)\n",
    "    \n",
    "    sent_id = torch.tensor(tokenized_text['input_ids'])\n",
    "    mask = torch.tensor(tokenized_text['attention_mask'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        initial_text = tokenizer.decode(sent_id[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Assuring that all 3 elements are in the GPU\n",
    "    model = model.to(device)\n",
    "    mask = mask.to(device)\n",
    "    sent_id = sent_id.to(device)\n",
    "\n",
    "    # model predictions\n",
    "    pred = model(sent_id, mask)\n",
    "    prob = torch.softmax(pred, dim=1)[0]\n",
    "\n",
    "    if prob[0] > prob[1]:\n",
    "        sentiment = \"Offensive\"\n",
    "    else:\n",
    "        sentiment = \"Non-Offensive\"\n",
    "        \n",
    "    pred = pred.detach().cpu().numpy()\n",
    "\n",
    "    return {initial_text:sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sentence I kill you it is predicting a non-offensive comment. This is wrong maybe due to BERT model has been trained\n",
    "# on longer sequences and shorter sequences may not provide enough context. Altought adding the param pad_to_max_length=True,\n",
    "# the sentence is still to short and it continues missing the prediction\n",
    "predict_offensive(\"I kill you\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_offensive(\"I don't like you\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
