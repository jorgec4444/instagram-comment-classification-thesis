{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a75548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "dataset = pd.read_csv('CleanTranslateDataset/final_dataset.csv', delimiter=',', encoding='ISO-8859-1')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1741658",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "\n",
    "\"\"\"\n",
    "This function autodetects the language of a comment and translates it to english\n",
    "\"\"\"\n",
    "def detect_translate(comment):\n",
    "    try:\n",
    "        translation = translator.translate(comment, dest = 'en').text\n",
    "    except:\n",
    "        translation = \"ERROR\"\n",
    "        \n",
    "    return translation\n",
    "\n",
    "\"\"\"\n",
    "This function iterates over all the rows of a dataset and translate each comment from its language to english\n",
    "\"\"\"\n",
    "def translate_dataset(df):\n",
    "    df = df.copy()\n",
    "    lang_accuracy = 0\n",
    "\n",
    "    # iterate over all rows\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        row['comment'] = detect_translate(row['comment'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4333e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataset = translate_dataset(dataset)\n",
    "#translated_dataset.to_csv(\"final_dataset_translated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the complete dataset to a pickle object in order to access to the data later\n",
    "\"\"\"with open('final_dataset_translated.pickle', 'wb') as handle:\n",
    "    pickle.dump(translated_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a684db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Reading it once it's already stored\n",
    "with open('final_dataset_translated.pickle', 'rb') as handle:\n",
    "    translated_dataset = pickle.load(handle)\n",
    "    \n",
    "print(all(translated_dataset == read_translated_dataset))\n",
    "translated_dataset\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea2180b",
   "metadata": {},
   "source": [
    "Shuffleing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737797ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataset = translated_dataset.sample(frac = 1)\n",
    "translated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87980883",
   "metadata": {},
   "source": [
    "Remove all the rows that contain the string \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataset = translated_dataset[~(translated_dataset == 'ERROR').any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#translated_dataset.to_csv(\"final_dataset_translated_shuffle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc39b5",
   "metadata": {},
   "source": [
    "At this moment of the preprocessing, I have used an external tool such as GoogleSheets with the help of its functions for filtering and the application of formulas in order to correctly clean the dataset. I also have labeled 1000 comments with a 1 meaning \"not ofensive comment\" and with a 0 meaning \"offensive comment\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8028eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the dataset after labeling an amount of data\n",
    "labeled_dataset = pd.read_csv('CleanTranslateDataset/final_dataset_labeled.csv',delimiter=',', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numeric values of the sentiment column and setting the non numeric ones to NaN\n",
    "numeric_col = pd.to_numeric(labeled_dataset['sentiment'], errors='coerce')\n",
    "\n",
    "# Find the last row that contains a float in the 'sentiment' column\n",
    "last_float_row = labeled_dataset[ pd.notna(numeric_col) & (numeric_col.dtype == float) ].tail(1)\n",
    "\n",
    "# Print the last row that contains a float in the 'sentiment' column\n",
    "print(f\"The last row that contains a float in the sentiment column is:\\n{last_float_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ba096",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the v1 of the full cleaned dataset that then we will use for training the model\n",
    "cleaned_dataset = labeled_dataset[:1420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.tail(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de4538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_dataset['sentiment'] = cleaned_dataset['sentiment'].astype(int)\n",
    "cleaned_dataset.tail(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb5249",
   "metadata": {},
   "source": [
    "Here I realised that there is an error, we have values with a number different to 0 or 1. Let's check how many there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e587693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After realising that there were values that weren't 0 or 1, checking them\n",
    "cleaned_dataset_check = cleaned_dataset[(cleaned_dataset['sentiment'] != 0 ) &  (cleaned_dataset['sentiment'] != 1 )]\n",
    "cleaned_dataset_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reading the comment, just changing from 2 (only different number from 0 or 1) to 1 (non ofensive)\n",
    "cleaned_dataset.loc[cleaned_dataset['sentiment'] == 2, 'sentiment'] = int(1)\n",
    "cleaned_dataset.tail(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again if there are still some different numbers different to 1 or 0\n",
    "cleaned_dataset_check = cleaned_dataset[(cleaned_dataset['sentiment'] != 0 ) &  (cleaned_dataset['sentiment'] != 1 )]\n",
    "cleaned_dataset_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b231b0",
   "metadata": {},
   "source": [
    "Finally we can save the dataset in order to use it to train or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced223e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
